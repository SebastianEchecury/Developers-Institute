{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70afd4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install spacy\n",
    "#!pip install spacy download en\n",
    "#!pip -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aaea99f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping chunkers\\maxent_ne_chunker.zip.\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\words.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "#import spacy\n",
    "#spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "from nltk import pos_tag, ne_chunk\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd7114d",
   "metadata": {},
   "source": [
    "<b>Exercise 1</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a7cd2a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Review': [\n",
    "        'At McDonald\\'s the food was ok and the service was bad.',\n",
    "        'I would not recommend this Japanese restaurant to anyone.',\n",
    "        'I loved this restaurant when I traveled to Thailand last summer.',\n",
    "        'The menu of Loving has a wide variety of options.',\n",
    "        'The staff was friendly and helpful at Google\\'s employees restaurant.',\n",
    "        'The ambiance at Bella Italia is amazing, and the pasta dishes are delicious.',\n",
    "        'I had a terrible experience at Pizza Hut. The pizza was burnt, and the service was slow.',\n",
    "        'The sushi at Sushi Express is always fresh and flavorful.',\n",
    "        'The steakhouse on Main Street has a cozy atmosphere and excellent steaks.',\n",
    "        'The dessert selection at Sweet Treats is to die for!'\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ccaf8d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    filtered_tokens = [word for word in tokens if word != '.']\n",
    "    #lemmatized = [token.lemma_ for token in filtered_tokens]\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b72c5e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b2d8bf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(len(data['Review'])):\n",
    "    data_copy['Review'][n] = preprocess_text(data_copy['Review'][n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "98d73245",
   "metadata": {},
   "outputs": [],
   "source": [
    "#doc = 'Apple is looking at buying U.K. startup for $1 billion'\n",
    "\n",
    "def perform_ner(text):\n",
    "    tags = pos_tag(text)\n",
    "    entities = ne_chunk(tags)\n",
    "    return(entities)\n",
    "    \n",
    "#perform_ner(doc.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "77f5f37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  at/IN\n",
      "  mcdonald/NN\n",
      "  's/POS\n",
      "  the/DT\n",
      "  food/NN\n",
      "  was/VBD\n",
      "  ok/JJ\n",
      "  and/CC\n",
      "  the/DT\n",
      "  service/NN\n",
      "  was/VBD\n",
      "  bad/JJ)\n",
      "(S\n",
      "  i/NN\n",
      "  would/MD\n",
      "  not/RB\n",
      "  recommend/VB\n",
      "  this/DT\n",
      "  japanese/JJ\n",
      "  restaurant/NN\n",
      "  to/TO\n",
      "  anyone/NN)\n",
      "(S\n",
      "  i/NN\n",
      "  loved/VBD\n",
      "  this/DT\n",
      "  restaurant/NN\n",
      "  when/WRB\n",
      "  i/NN\n",
      "  traveled/VBD\n",
      "  to/TO\n",
      "  thailand/VB\n",
      "  last/JJ\n",
      "  summer/NN)\n",
      "(S\n",
      "  the/DT\n",
      "  menu/NN\n",
      "  of/IN\n",
      "  loving/NN\n",
      "  has/VBZ\n",
      "  a/DT\n",
      "  wide/JJ\n",
      "  variety/NN\n",
      "  of/IN\n",
      "  options/NNS)\n",
      "(S\n",
      "  the/DT\n",
      "  staff/NN\n",
      "  was/VBD\n",
      "  friendly/JJ\n",
      "  and/CC\n",
      "  helpful/JJ\n",
      "  at/IN\n",
      "  google/NN\n",
      "  's/POS\n",
      "  employees/NNS\n",
      "  restaurant/VBP)\n",
      "(S\n",
      "  the/DT\n",
      "  ambiance/NN\n",
      "  at/IN\n",
      "  bella/NN\n",
      "  italia/NN\n",
      "  is/VBZ\n",
      "  amazing/JJ\n",
      "  ,/,\n",
      "  and/CC\n",
      "  the/DT\n",
      "  pasta/NN\n",
      "  dishes/NNS\n",
      "  are/VBP\n",
      "  delicious/JJ)\n",
      "(S\n",
      "  i/NN\n",
      "  had/VBD\n",
      "  a/DT\n",
      "  terrible/JJ\n",
      "  experience/NN\n",
      "  at/IN\n",
      "  pizza/NN\n",
      "  hut/VBP\n",
      "  the/DT\n",
      "  pizza/NN\n",
      "  was/VBD\n",
      "  burnt/VBN\n",
      "  ,/,\n",
      "  and/CC\n",
      "  the/DT\n",
      "  service/NN\n",
      "  was/VBD\n",
      "  slow/JJ)\n",
      "(S\n",
      "  the/DT\n",
      "  sushi/NN\n",
      "  at/IN\n",
      "  sushi/NN\n",
      "  express/NN\n",
      "  is/VBZ\n",
      "  always/RB\n",
      "  fresh/JJ\n",
      "  and/CC\n",
      "  flavorful/JJ)\n",
      "(S\n",
      "  the/DT\n",
      "  steakhouse/NN\n",
      "  on/IN\n",
      "  main/JJ\n",
      "  street/NN\n",
      "  has/VBZ\n",
      "  a/DT\n",
      "  cozy/NN\n",
      "  atmosphere/RB\n",
      "  and/CC\n",
      "  excellent/JJ\n",
      "  steaks/NNS)\n",
      "(S\n",
      "  the/DT\n",
      "  dessert/JJ\n",
      "  selection/NN\n",
      "  at/IN\n",
      "  sweet/JJ\n",
      "  treats/NNS\n",
      "  is/VBZ\n",
      "  to/TO\n",
      "  die/VB\n",
      "  for/IN\n",
      "  !/.)\n"
     ]
    }
   ],
   "source": [
    "for r in data_copy['Review']:\n",
    "    print(perform_ner(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "16c635b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VBZ: verb, present tense, 3rd person singular\n",
      "    bases reconstructs marks mixes displeases seals carps weaves snatches\n",
      "    slumps stretches authorizes smolders pictures emerges stockpiles\n",
      "    seduces fizzes uses bolsters slaps speaks pleads ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package tagsets to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package tagsets is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('tagsets')\n",
    "nltk.help.upenn_tagset('VBZ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd90844",
   "metadata": {},
   "source": [
    "<b> Exercise 2</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9e0dda4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "96fb9e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=data_copy, min_count=1, vector_size=100, window=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c3c94064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(model.vector_size)  # Imprime la dimensi√≥n de los vectores\n",
    "\n",
    "# Obtener el vocabulario\n",
    "words = list(model.wv.index_to_key)\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b760ed1",
   "metadata": {},
   "source": [
    "A vector dimension is the amount of different features a word have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "445c7542",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 31.6/31.6MB downloaded\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "import gensim.downloader as api\n",
    "nltk.download('punkt')\n",
    "\n",
    "dataset = api.load(\"text8\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3ad36e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(model.wv.index_to_key)[:50]\n",
    "tokenized_data = [word_tokenize(doc) for doc in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "12424fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=tokenized_data, vector_size=100, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5ecec686",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "The vocab attribute was removed from KeyedVector in Gensim 4.0.0.\nUse KeyedVector's .key_to_index dict, .index_to_key list, and methods .get_vecattr(key, attr) and .set_vecattr(key, attr, new_val) instead.\nSee https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [67]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel vocabulary size:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab\u001b[49m))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py:661\u001b[0m, in \u001b[0;36mKeyedVectors.vocab\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    659\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    660\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvocab\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 661\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m    662\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe vocab attribute was removed from KeyedVector in Gensim 4.0.0.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    663\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse KeyedVector\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms .key_to_index dict, .index_to_key list, and methods \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    664\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.get_vecattr(key, attr) and .set_vecattr(key, attr, new_val) instead.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    665\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSee https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    666\u001b[0m     )\n",
      "\u001b[1;31mAttributeError\u001b[0m: The vocab attribute was removed from KeyedVector in Gensim 4.0.0.\nUse KeyedVector's .key_to_index dict, .index_to_key list, and methods .get_vecattr(key, attr) and .set_vecattr(key, attr, new_val) instead.\nSee https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4"
     ]
    }
   ],
   "source": [
    "print(\"Model vocabulary size:\", len(model.wv.vocab))\n",
    "#print(\"Vector size:\", model.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b879160c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Key 'woman' not present\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [63]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m example_result \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmost_similar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpositive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwoman\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mking\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnegative\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msavory\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtopn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(example_result)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py:773\u001b[0m, in \u001b[0;36mKeyedVectors.most_similar\u001b[1;34m(self, positive, negative, topn, clip_start, clip_end, restrict_vocab, indexer)\u001b[0m\n\u001b[0;32m    771\u001b[0m     mean\u001b[38;5;241m.\u001b[39mappend(weight \u001b[38;5;241m*\u001b[39m key)\n\u001b[0;32m    772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 773\u001b[0m     mean\u001b[38;5;241m.\u001b[39mappend(weight \u001b[38;5;241m*\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[0;32m    774\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_index_for(key):\n\u001b[0;32m    775\u001b[0m         all_keys\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_index(key))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py:438\u001b[0m, in \u001b[0;36mKeyedVectors.get_vector\u001b[1;34m(self, key, norm)\u001b[0m\n\u001b[0;32m    414\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_vector\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    415\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get the key's vector, as a 1D numpy array.\u001b[39;00m\n\u001b[0;32m    416\u001b[0m \n\u001b[0;32m    417\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    436\u001b[0m \n\u001b[0;32m    437\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 438\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m norm:\n\u001b[0;32m    440\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfill_norms()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py:412\u001b[0m, in \u001b[0;36mKeyedVectors.get_index\u001b[1;34m(self, key, default)\u001b[0m\n\u001b[0;32m    410\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m default\n\u001b[0;32m    411\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 412\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKey \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not present\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Key 'woman' not present\""
     ]
    }
   ],
   "source": [
    "example_result = model.wv.most_similar(positive=['woman', 'king'], negative=['savory'], topn=1)\n",
    "print(example_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ad4a48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
